{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "945fa928",
   "metadata": {},
   "source": [
    "# Inversion and Optimisation Assessment 1 General Feedback\n",
    "\n",
    "The goal of this assessment was to have students explore various aspects of inversion problems with the goal of having students understand better the data acquisition, physical intuition and some technical aspects of such problems. Since assessment 2 was going to be focused more on theoretical aspects of the course, this assessment was more based around using knowledge of physics to interpret data, and then using this knowledge to inform how improvements could be made/better results potentially obtained.\n",
    "\n",
    "The assessment was, by design, fairly open ended and hence a range of different solutions was possible. Solutions which obtained higher marks were those well thought out, well structured and well explained.\n",
    "\n",
    "Below are some general comments regarding the submissions which are followed by a discussion of each part, where the question and it's goals are discussed followed by what was being looked for in a good answer and some common pitfalls.\n",
    "\n",
    "### General comments\n",
    "\n",
    "- Make sure plot axes are labeled and plots are, where appropriate, captioned.\n",
    "- Remember that after creating a plot, you don't have to show it immediately. `plot_x.show()` could be placed much later in a notebook, e.g. near relevant text discussing it, resulting in a cleaner presentation of the work.\n",
    "- Some students notebooks were missing/not displaying plots, often due to them not being uploaded or placed in an incorrect folder. It's a good idea to check `GitHub` prior to submission to ensure plots etc. are displaying as intended.\n",
    "- Citing too much of someone else's text is not a good idea. Even if the source is being provided, citing text from other works (i.e. putting someone else's text into your work) should be done sporadically and clearly backed up with your own explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01177c28",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "(a) For this part, you were provided with two shot records and asked to discuss these and the difference between them. It was required to explain the various features observed in the images in terms of the physics of wave-propagation.\n",
    "\n",
    "Some important features that should have been highlighted:\n",
    "- The first feature to point out is direct arrival of the wave from the source. In both true and smoothed models, the velocity is roughly $1kms^{-1}$ in the upper layer. Therefore the wave will arrive at $t\\approx D/V$ where $V$ is the velocity of pressure waves, $1kms^{-1}$, and $D$ is the distance of the receiver from the source. (Note that this relation allows you to work out the expected slope of the direct arrival 'wedge'). Further, as expected, the profile/amplitude of the direct arrival matches that of the Ricker source with amplitudes decaying with distance from the source.\n",
    "- Another feature to point out, again present in both the true and smoothed model, is the presence of the reflected wave from the left-hand side boundary. It should be noted that this a numerical artifact and in a real scenario such reflections would only be present in the smoothed/synthetic data.\n",
    "- As pressure waves travel through media with non-constant velocities they will undergo refraction and reflection. In the true model, the complex geology (many sudden changes in velocity of pressure waves) is responsible for the complex pattern observed at receivers at various points in time after the direct arrival. These features are however less pronounced and largely absent in the smoothed model - this is because the affect of the (Gaussian) smoothing has been to reduce velocity gradients - and importantly - remove step changes thus largely eliminating reflections from internal features.\n",
    "- There were other features that it was reasonable to draw attention to (e.g. why reflection from right and bottom are not present here) but above are the main ones.\n",
    "\n",
    "Some common errors:\n",
    "- Explaining what a shot record is instead of explaining what these shot records represent.\n",
    "- Describing what is in the image instead of explaining what is seen in terms of the physics.\n",
    "- Confusing the role of the smooth model.\n",
    "- Not correctly explaining the direct arrival profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5d203",
   "metadata": {},
   "source": [
    "(b) Here, using a form of `alpha` similar to that seen in lectures (e.g. `alpha = const / mmax(update)` etc.) it was required to explore the convergence of the algorithm over a range of `const`'s. (Note that one reason for doing this was to help optimise your line search algorithms in part c).\n",
    "\n",
    "Recall that in the gradient descent scheme, `alpha` is approximating the inverse Hessian, and hence the range of `alpha` for which the algorithm will converge is closely related to $1/\\lambda_{max}$ and $1/\\lambda_{min}$, where $\\lambda_{max}$ and $\\lambda_{min}$ are the largest and smallest eigenvalues of the Hessian respectively.\n",
    "\n",
    "As we approach the minimum, generally speaking, the Hessian will tend towards being singular and ill-conditioned, hence the eigenvalues will become large meaning `alpha` will need to become small.\n",
    "\n",
    "In this particular problem, for the form given above, `const` between ~0.01 and just under 0.06 gave reasonable results, with smaller values being 'slow' but leading to smooth convergence over a larger number of iterations. Thus `alpha` was fairly sensitive requiring choices to be well within an order of magnitude of each other.\n",
    "\n",
    "Good answers to this question would have included a clear presentation of results in either a graphical (preferable) or tabular form. Results would have demonstrated an `alpha` showing poor convergence on either extreme along with a clear explanation of the results presented.\n",
    "\n",
    "Generally, students did well in this section. The main pitfalls included:\n",
    "- An inadequate/unclear summary of results.\n",
    "- Lack of discussion regarding the results observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9aa50",
   "metadata": {},
   "source": [
    "(c) Here it was required to adapt the 'simple line search' algorithm seen in a previous lecture to work with the FWI algorithm being used here.\n",
    "\n",
    "The code could largely be lifted from that given in the lecture, but a few modifications were required (and especially to make the algorithm efficient).\n",
    "\n",
    "Firstly, since $\\nabla f(\\mathbf{m})$ is a vector, the Armijo rule needs to be modified to\n",
    "\n",
    "\\begin{equation*}\n",
    " f(\\mathbf{m}-\\alpha\\nabla f(\\mathbf{m}))-f(\\mathbf{m}) \\leq \\beta\\alpha\\nabla f(\\mathbf{m})^T\\mathbf{p},\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\beta$ is a scalar value between 0 and 1 and $\\mathbf{p}$ is the search direction: a suitable choice here would be\n",
    "\n",
    "\\begin{equation*}\n",
    " \\mathbf{p}=-\\frac{\\nabla f(\\mathbf{m})}{||\\nabla f(\\mathbf{m})||}.\n",
    "\\end{equation*}\n",
    "\n",
    "Generally it's better to start with a smallish value of $\\beta$ and then increase it to see what you can 'get away with'. The value of $\\beta$ chosen should have had a sensible default but also an option for the user to pass in their desired value.\n",
    "\n",
    "It was then important to clearly explain how the algorithm (and its inputs/outputs) mapped to the FWI problem (i.e. not just a 1d-problem of some general function) and ensure the code worked efficiently. Note that an optimized code converges faster than in the absence of using a line search.\n",
    "\n",
    "Some common pitfalls included:\n",
    "- The most prominent issue was inefficient implementations. Many of you re-used the `fwi_gradient` function in this routine to compute the updated objective function: This was fine, but notice that the main computation done in that routine, that of computing the adjoint, is redundant. Hence, that function should have been modified to include a suitable flag to ensure no redundant computation was carried out.\n",
    "- Not detailing how the parameters in the original line search algorithm map to those being used in the FWI algorithm when explain the algorithm. When explaining the algorithm, many copied and pasted material from the earlier lecture instead of generalizing it to the 'scalar function of a vector field' form required here. Others just generally stated the steps of algorithm instead of utilizing mathematics to explain and justify it.\n",
    "- The gradient (`-direction`) and initial model used in the `alpha` optimisation loop should be the same within each iteration. Some codes erroneously updated one (or both) of these during the `alpha` optimisation loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51465a6b",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "The first (minor) comment regarding this part, which is also true for part 3, is that many students copied a good deal of redundant code from their first notebook into this notebook. It would have been better to copy only the components from part 1 **required** for this part across e.g. there was no need to reproduce shot records or copy much of the explanatory parts of the notebook across.\n",
    "\n",
    "In this section, the goal was to utilize your physical and mathematical knowledge to inform decisions regarding acquisition geometries that could result in better (or worse) images. Whilst for the sake of experimentation it was perfectly acceptable to consider non-physical (i.e. not feasible in practice) geometries, this should be mentioned and explained.\n",
    "\n",
    "Thinking about the problem from a more abstract mathematical point of view, the objective function $\\phi(\\mathbf{m})$ lives in a phase space of dimension 'length of $\\mathbf{m}$'. The goal is to find the minimum (deepest valley) of this function $\\phi$. To do so, we require a good estimation of the gradient which in turn requires sufficient information to produce a good approximation. In a linear algebra sense, we require our data sets $\\mathbf{p}$ and $\\mathbf{d}$ do be sufficiently linearly independent to allow us to form a good estimate of the gradient. This requires, e.g.:\n",
    "- Shots records over a suitable time-frame for the geometry.\n",
    "- Source and receiver placement such that waves that have passed through as much of the domain as possible are being collected.\n",
    "- We also want to avoid data redundancy e.g. having two receivers based at the same location would mean that these two sets are completely linearly dependent.\n",
    "\n",
    "Some comments regarding the solutions presented are as follows:\n",
    "- Generally speaking, students attempted a good range of source and receiver locations.\n",
    "- However, explanation and justification regarding source and receiver placements and numbers and data acquisition times (simulation run time) was generally lacking.\n",
    "- It should be shown (or at least hypothesized) that geometries demonstrate good illumination (by illumination we mean that suitable wave energy-density has been propagated throughout the domain and collected at the receivers).\n",
    "- When proposing new geometries, it's a good idea to justify the simulation time by considering $distance\\_travelled = |velocity|\\times simulation\\_time$. Simulation time can then be chosen such that it's (roughly) large enough to collect all relevant reflection and refraction data but not too large so it's eventually only collecting reflection data. A common issue was that students chose geometries capable of producing good images, but did not adjust the simulation time suitably and thus ended up with 'bad' images (and weren't able to explain why).\n",
    "- Having a larger number of sources and/or sinks by definition leads to a higher value of the objective function. Therefore, comparing the objective function or a simulation with $N$ receivers to one with $M$ receivers, a suitable normalisation is required to make quantitative comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce463f",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "(a) First of all, there was no need to run any inversion problems for this part. Forward simulations were sufficient. Generally, students clearly understood that the role of the absorbing boundaries was to reduce artificial reflections in an attempt to better mimic the reality of an infinite domain (where waves are free to propagate without limit).\n",
    "\n",
    "Given sufficient time, the initial wave should have left the domain (this time can again be roughly established using simple distance over time calculations). This is a good time to choose to measure, say, the $L_2$-norm of the wave-field (but the norm at only that sensibly chosen point in time, not of the entire wave-field throughout time). Then, for large absorbing boundaries we would expect the norm to be smaller than that of simulations with thinner absorbing layers (since less reflection data would be present). Another, and possible better, method for measuring the effectiveness would be finding the simulation time where, to within some tolerance, the norm of the wave-field becomes zero. For thin layers, this would be large, for thick layers this would be much smaller. Then, we could plot e.g. 'time to reach this norm' vs 'time to run the computation' to ascertain whether this relationship is linear or non-linear etc.\n",
    "\n",
    "Overall, whilst students did a pretty reasonable job on this part, explanations could have been presented in a cleaner and more rigorous manner by utilizing some of the ideas outlined above.\n",
    "\n",
    "(b) An important aspect of this part, which many people missed, was (based on insight from part a) deciding on a simulation that could be considered the 'truth' e.g. choose a suitable large boundary layer width and use that (and only that) to generate the 'true' data. Inversion should then be conducted using only that data set as the true model. That is, the 'true' model data should have been the same in all simulations conducted in this section. In fact, the receiver data for such a simulation could have been dumped to file, and then simply read in during each of the subsequent inversion tests making things far more efficient.\n",
    "\n",
    "Changing the boundary layer width of both the true and smoothed models simultaneously will often (depending on acquisition geometry) lead to unreliable conclusions.\n",
    "\n",
    "Generally, with the data produced, the class did a pretty good job at describing the observed results - however some explanations or lines of questioning results could have been improved. For example, if with increasing absorbing boundary width results are getting 'worse', it should be questioned whether the experiment being conducted is of relevance or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (devito)",
   "language": "python",
   "name": "devito"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
