{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Mathematics  <a class=\"tocSkip\">\n",
    "\n",
    "## Probability (and some first steps towards Machine Learning) <a class=\"tocSkip\">\n",
    "    \n",
    "### Homework Exercises - Solutions <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Homework\" data-toc-modified-id=\"Homework-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Homework</a></span><ul class=\"toc-item\"><li><span><a href=\"#Homework---Covariance-matrices-for-the-Iris-flowers-per-species\" data-toc-modified-id=\"Homework---Covariance-matrices-for-the-Iris-flowers-per-species-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Homework - Covariance matrices for the Iris flowers per species</a></span></li><li><span><a href=\"#Homework---Computing-the-covariance-matrix\" data-toc-modified-id=\"Homework---Computing-the-covariance-matrix-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Homework - Computing the covariance matrix</a></span></li><li><span><a href=\"#Homework---Die-rolling-experiment\" data-toc-modified-id=\"Homework---Die-rolling-experiment-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Homework - Die-rolling experiment</a></span></li><li><span><a href=\"#Homework---The-Gaussian-integral\" data-toc-modified-id=\"Homework---The-Gaussian-integral-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Homework - The Gaussian integral</a></span></li><li><span><a href=\"#Homework---Normal-distribution-plotting\" data-toc-modified-id=\"Homework---Normal-distribution-plotting-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Homework - Normal distribution plotting</a></span></li><li><span><a href=\"#Homework---Cumulative-distribution/density-function-(CDF)\" data-toc-modified-id=\"Homework---Cumulative-distribution/density-function-(CDF)-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Homework - Cumulative distribution/density function (CDF)</a></span></li><li><span><a href=\"#Homework---Naive-Bayes-classifier\" data-toc-modified-id=\"Homework---Naive-Bayes-classifier-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Homework - Naive Bayes classifier</a></span></li><li><span><a href=\"#Homework---The-logistic-function-and-its-derivative\" data-toc-modified-id=\"Homework---The-logistic-function-and-its-derivative-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Homework - The logistic function and its derivative</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "div.optional {\n",
    "    display: block;\n",
    "    background-color: #d7e2ff;\n",
    "    border-color: #d7e2ff;\n",
    "    border-left: 5px solid #d7e2ff;\n",
    "    padding: 0.5em;\n",
    "}\n",
    "div.advanced {\n",
    "    display: block;\n",
    "    background-color: #fff4d7;\n",
    "    border-color: #fff4d7;\n",
    "    border-left: 5px solid #fff4d7;\n",
    "    padding: 0.5em;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "# https://seaborn.pydata.org/\n",
    "# \"Seaborn is a Python data visualization library based on matplotlib. \n",
    "# It provides a high-level interface for drawing attractive and informative statistical graphics.\"\n",
    "import seaborn as sns\n",
    "# switch to seaborn figure aesthetic defaults\n",
    "#sns.set_theme()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Covariance matrices for the Iris flowers per species\n",
    "\n",
    "Recreate the covariance \"eye-ball\" correlation guessing and associated calculation for each Iris flower species in turn, i.e. do it on a per-colour basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Computing the covariance matrix\n",
    "\n",
    "Recall from class we used Pandas `cov()` to compute the covariance matrix for the first four data columns of the Iris dataset (repeated in next well).\n",
    "\n",
    "Of course this is convenient, but doesn't help confirm out mathematical understanding of what is going on.\n",
    "\n",
    "Try computing this $4\\times 4$ matrix yourself from first principles using NumPy alone (and not using NumPy's `cov()`!!\n",
    "\n",
    "Speccifically, convert the Pandas data frame for the first 4 columns of data to a NumPy array (which should then be of size 50 x 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_virginica_df.iloc[:, :-1].cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Die-rolling experiment\n",
    "\n",
    "Investigate how the probabilities computed for the die-rolling experiment equalise as you increase the number of times you roll the die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - The Gaussian integral\n",
    "\n",
    "A useful definite integral to know is the area under the function $e^{-x^2}$ over the whole real line:\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} e^{-x^2}\\, dx = \\sqrt{\\pi}$$\n",
    "\n",
    "This result is known as the [Gaussian integral](https://en.wikipedia.org/wiki/Gaussian_integral>).\n",
    "\n",
    "Read the description at the above link for how this integral can be (relatively) easily established if you know about polar coordinates and know the \"trick\".\n",
    "\n",
    "<br>\n",
    "\n",
    "Once we have this key result we can establish that \n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} e^{-\\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right)^2 }\\, dx = \\sigma\\sqrt{2\\pi}$$\n",
    "\n",
    "and thus by dividing through by the quantity on the RHS we have a function\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right)^2 }$$\n",
    "\n",
    "(note that this is the [**Gaussian function**](https://en.wikipedia.org/wiki/Gaussian_function))which has the property that its integral over the entire real line is unity.\n",
    "\n",
    "<br>\n",
    "\n",
    "Can you see how to establish that \n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} e^{-x^2}\\, dx = \\sqrt{\\pi}  \n",
    "\\implies\n",
    "\\int_{-\\infty}^{\\infty} e^{-\\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right)^2 }\\, dx = \\sigma\\sqrt{2\\pi}\n",
    "$$\n",
    "\n",
    "through two changes of variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Normal distribution plotting\n",
    "\n",
    "As mentioned in class, take the code that randomly draws data from a normal distribution, plot it with different numbers of bins, sample size etc, and check how well it agrees with the normal distribution/Gaussian function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Cumulative distribution/density function (CDF)\n",
    "\n",
    "Recall the following plot from the lecture that used `normal_distribution.cdf`.\n",
    "\n",
    "Recreate this plot using only data obtained from `normal_distribution.pdf` and the mathematical definition of the CDF in terms of the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "standard_deviation = 0.1\n",
    "\n",
    "# Define the normal distribution\n",
    "normal_distribution = st.norm(mean, standard_deviation)\n",
    "\n",
    "# Compute CDF values at a sequence of x locations between -1 and 1\n",
    "x_values = np.linspace(-1, 1, 100)\n",
    "y_values = normal_distribution.cdf(x_values)\n",
    "\n",
    "# Plot PDF\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$P(X\\leq x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Naive Bayes classifier\n",
    "\n",
    "\n",
    "Repeat the naive Bayes classification for the Iris dataset, but use [sklearn.model_selection.train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split the dataset into test and training sets, using the training set for training and test set to calculate the accuracy in the end. \n",
    "\n",
    "Below is the code and application from class that gave an accuracy of 96%.\n",
    "\n",
    "If we more correctly split our training and test data how might we expect our accuracy to change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the means and standard deviations for our four features and three species\n",
    "means = irisdf.groupby('target').mean().to_numpy()\n",
    "stds = irisdf.groupby('target').std().to_numpy()\n",
    "\n",
    "\n",
    "# Define the normal distributions for each\n",
    "distributions = []\n",
    "for mvec, sdvec in zip(means, stds):\n",
    "    distributions.append([st.norm(m, sd) for m, sd in zip(mvec, sdvec)])\n",
    "\n",
    "# Since the smallest measurement in the dataset is 0.1 cm,\n",
    "# we use the range (x-eps) - (x+eps) (with eps=0.05) to calculate the probability.\n",
    "def calc_probability(x, distribution, eps=0.05):\n",
    "    # use the cdf = cumulative density function\n",
    "    return distribution.cdf(x+eps) - distribution.cdf(x-eps)\n",
    "\n",
    "def cls_probablility(data, cls, distributions):\n",
    "    # initialise p - as we're going to be multiplying probabilities, initialise it to 1\n",
    "    p = 1\n",
    "    # for every feature, calculate its probability and multiply the results together\n",
    "    for feat in range(4):\n",
    "        p *= calc_probability(data[feat], distributions[cls][feat])    \n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "def calc_likelihood(data):\n",
    "    class_probs = []\n",
    "    for cls in range(3):\n",
    "        p = cls_probablility(data, cls, distributions)\n",
    "        class_probs.append(p)\n",
    "    return class_probs\n",
    "\n",
    "\n",
    "\n",
    "# Subscripting to remove the last column which is the target variable\n",
    "# these are therefore the means and stds of the entire 150 rows of data, \n",
    "# i.e. all of our measurements\n",
    "means = irisdf.mean().to_numpy()[0:4]\n",
    "stds = irisdf.std().to_numpy()[0:4]\n",
    "\n",
    "prior_dists = [st.norm(m, s) for m, s in zip(means, stds)]\n",
    "\n",
    "def calc_prior_X(data):\n",
    "    p = 1\n",
    "    for feat in range(4):\n",
    "        p *= calc_probability(data[feat], prior_dists[feat])\n",
    "    return p\n",
    "\n",
    "\n",
    "def calc_naive_bayes(data):\n",
    "    likelihood = calc_likelihood(data)\n",
    "    # From the data, we know that all three classes are equally likely\n",
    "    class_prior = [0.33, 0.33, 0.33]\n",
    "    data_prior = calc_prior_X(data)\n",
    "    \n",
    "    class_densities = [(l*cp) / data_prior for l, cp in zip(likelihood, class_prior)]\n",
    "    class_probs = [cd / sum(class_densities) for cd in class_densities]\n",
    "    \n",
    "    return class_probs\n",
    "\n",
    "\n",
    "\n",
    "# Now we will be using our trained model to do inference \n",
    "predictions = [np.argmax(calc_naive_bayes(X)) for X in iris['data']]\n",
    "\n",
    "correct_predictions = [1 if prediction==target else 0 for prediction, target in zip(predictions, iris['target'])]\n",
    "\n",
    "accuracy = float(sum(correct_predictions)/len(correct_predictions))\n",
    "\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - The logistic function and its derivative\n",
    "\n",
    "Plot the logistic function\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "Compute and plot its derivative over the interval $z \\in [-10,10]$.\n",
    "\n",
    "How would you update this function so that it was centred at $z=5$, and had a \"tighter\" (i.e. faster) jump from zero to one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "557.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
