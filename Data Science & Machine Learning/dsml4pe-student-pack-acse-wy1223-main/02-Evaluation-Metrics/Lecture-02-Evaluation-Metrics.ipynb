{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87101ca1-0910-4a85-a7a9-e4e81c695e98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Day 2**: Performance metrics üìè (***live in 1.49/1.50***)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00302d80-9b13-4bcf-a238-311aaced1466",
   "metadata": {},
   "source": [
    "# The two cells below load some helper functions used in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051b776-0b86-4d23-8be6-dee6dff545ee",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac890393-4cec-4522-8b63-0a5ba68e9199",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO LOAD GRAPHIC GENERATING FUNCTION\n",
    "\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def calculate_proba(x, threshold):\n",
    "    data = np.linspace(-5, 5, num=11)\n",
    "    true_class = [0,0,1, 0, 0, 1, 0, 1, 0, 1, 1]\n",
    "    proba = sigmoid(data)\n",
    "    predictions = [1 if p  >= threshold else 0 for p in proba]\n",
    "    \n",
    "    return (data, true_class, proba, predictions)\n",
    "    \n",
    "\n",
    "def calculate_matrix(predictions, true_class):\n",
    "    cf_data = list(zip(predictions, true_class))\n",
    "    tp = sum([1 if d==(1, 1) else 0 for d in cf_data])\n",
    "    tn = sum([1 if d==(0, 0) else 0 for d in cf_data])\n",
    "    fp = sum([1 if d==(1, 0) else 0 for d in cf_data])\n",
    "    fn = sum([1 if d==(0, 1) else 0 for d in cf_data])\n",
    "    \n",
    "    #array = [[tp,fp],[tn,fn]]\n",
    "    array = [[1,2],[3,4]]\n",
    "    \n",
    "    df_cm = pd.DataFrame(array, index = ['Negative', 'Positive'],\n",
    "                  columns = ['Negative', 'Positive'])\n",
    "    \n",
    "    annotations = pd.DataFrame([[f'TN\\n{tn}',f'FP\\n{fp}'],[f'FN\\n{fn}',f'TP\\n{tp}' ]])\n",
    "    return df_cm, annotations\n",
    "\n",
    "def calculate_metrics(predictions, true_class):\n",
    "    precision = precision_score(true_class, predictions,zero_division=0)\n",
    "    recall = recall_score(true_class, predictions)\n",
    "    f1 = f1_score(true_class, predictions)\n",
    "    accuracy = accuracy_score(true_class, predictions)\n",
    "    return  precision, recall, accuracy, f1\n",
    "\n",
    "def update_original(threshold = 0.5):\n",
    "    data, true_class, proba, predictions = calculate_proba(x, threshold)\n",
    "    df_cm = calculate_matrix(predictions, true_class)\n",
    "    \n",
    "    axes[0][1].clear()\n",
    "    axes[1][0].clear()\n",
    "    sns.heatmap(df_cm, annot=True, ax=axes[0][1],cbar=False, cmap='Purples')\n",
    "    threshold_line.set_ydata()\n",
    "    metrics = calculate_metrics(predictions, true_class)\n",
    "    \n",
    "    axes[1][0].barh(['Precision','Recall'],metrics)\n",
    "    \n",
    "    fig.canvas.draw_idle()\n",
    "  \n",
    "def create_plot(threshold = 0.5):\n",
    "    \n",
    "    fig, axes = plt.subplots(2,2, figsize=(10, 10))\n",
    "    draw_plot(axes, threshold)\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "def separate_classes(data, true_class, predictions, proba):\n",
    "    all_data = zip(data, true_class, predictions, proba)\n",
    "    \n",
    "    tp = []\n",
    "    tn = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    \n",
    "    for d in all_data:\n",
    "        if d[1] == d[2] and d[1] == 0:\n",
    "            tn.append(d) \n",
    "        if d[1] == d[2] and d[1] == 1:\n",
    "            tp.append(d) \n",
    "        if d[1] != d[2] and d[1] == 1:\n",
    "            fn.append(d) \n",
    "        if d[1] != d[2] and d[1] == 0:\n",
    "            fp.append(d) \n",
    "    \n",
    "    return {'tp':tp, 'tn':tn, 'fp':fp, 'fn':fn}\n",
    "        \n",
    "\n",
    "def draw_plot(axes, threshold):\n",
    "    x = np.linspace(-6, 6)\n",
    "    data, true_class, proba, predictions = calculate_proba(x, threshold)\n",
    "    label_font = {'size':'12', 'weight':'bold'}\n",
    "    \n",
    "    classes = separate_classes(data, true_class, predictions, proba)\n",
    "    \n",
    "    axes[0][0].axhspan(-.18, threshold, facecolor='dimgrey', alpha=0.2)\n",
    "    axes[0][0].axhspan(threshold, 1.18, facecolor='powderblue', alpha=0.2)\n",
    "    \n",
    "    sigmoid_curve, = axes[0][0].plot(x, sigmoid(x))\n",
    "    threshold_line, = axes[0][0].plot(x, np.ones(len(x))*threshold, c='r', linestyle='--')\n",
    "    axes[0][0].set_xlim(-6,6)\n",
    "    axes[0][0].set_ylim(-.18,1.18)\n",
    "    axes[0][0].set_xlabel(\"Feature Space\", fontdict=label_font)\n",
    "    axes[0][0].set_ylabel(\"Probability\", fontdict=label_font)\n",
    "    \n",
    "    axes[0][0].tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False)\n",
    "    \n",
    "    #axes[0][0] = axes[0][0].scatter(data, sigmoid(data), marker = symbols, s=400, c=true_class)\n",
    "    \n",
    "    colors = {'tp':'darkorchid', 'tn':'mediumpurple', 'fp':'lightcoral', 'fn':'lightsalmon'}\n",
    "    \n",
    "    for k, v in classes.items():\n",
    "        if k == 'tp' or k == 'fn':\n",
    "            m = 's'\n",
    "            s = 300\n",
    "        else:\n",
    "            m = 'o'\n",
    "            s = 400\n",
    "        c = colors.get(k)\n",
    "        \n",
    "        values = np.array([d[0] for d in v])\n",
    "        \n",
    "        axes[0][0].scatter(values,sigmoid(values), marker=m,s=s, color=c)\n",
    "    \n",
    "    precision, recall, accuracy, f1 = calculate_metrics(predictions, true_class)\n",
    "        \n",
    "    axes[1][0].barh(['Precision','Recall'],[precision, recall], color=['darkgreen','coral'])\n",
    "    axes[1][1].barh(['Accuracy','F1-Score'],[accuracy, f1], color=['mediumturquoise','plum'])\n",
    "    axes[1][1].yaxis.set_label_position(\"right\")\n",
    "    axes[1][1].yaxis.tick_right()\n",
    "    \n",
    "    axes[1][1].annotate(  f'{f1:.02}', (f1/2, 1), size=12, weight='bold', color='white')\n",
    "    axes[1][1].annotate(f'{accuracy:.01%}', (accuracy/2, 0),size=12, weight='bold', color='white')\n",
    "    axes[1][0].annotate(  f'{precision:.01%}', (precision/2, 0), size=12, weight='bold', color='white')\n",
    "    axes[1][0].annotate(f'{recall:.01%}', (recall/2, 1),size=12, weight='bold', color='white')\n",
    "    \n",
    "    axes[1][0].set_xlim(0,1)\n",
    "    axes[1][1].set_xlim(0,1)\n",
    "    df_cm, annotations = calculate_matrix(predictions, true_class)\n",
    "    \n",
    "    #create a discrete color mapping\n",
    "    colors = ['darkorchid', 'lightcoral','lightsalmon','mediumpurple']\n",
    "    levels = [0,1,2,3,4]\n",
    "    cmap, norm = mpl.colors.from_levels_and_colors(levels=levels, colors=colors)\n",
    "\n",
    "    cfm = sns.heatmap(df_cm,square=True, annot=annotations,fmt='', \n",
    "                      ax=axes[0][1],cbar=False, linewidth=.5, linecolor='k',\n",
    "                      annot_kws={\"size\": 14,'weight':'bold'}, cmap=cmap)\n",
    "    \n",
    "    axes[0][1].set_xlabel('Predicted labels', fontdict=label_font);\n",
    "    axes[0][1].set_ylabel('Actual labels', fontdict=label_font);\n",
    "    \n",
    "    return None\n",
    "    \n",
    "\n",
    "def update_plot(threshold = 0.5):\n",
    "    \n",
    "    for ax in axes.flatten():\n",
    "        ax.clear()\n",
    "    \n",
    "    draw_plot(axes, threshold)\n",
    "    \n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "\n",
    "\n",
    "def draw_roc_plot(select, auc, compare, ax):\n",
    "    #plt.close()\n",
    "    fpr= np.array([0,.03,.06,.11,.2,.3,.5,1])\n",
    "    tpr =np.array([0,.3,.55,.8,.9,.95,.98,1])\n",
    "    ratio = tpr[1:]/fpr[1:]\n",
    "    text_y_pos = [0,0.01,.2, .35, .4, .45, .6, .5]\n",
    "    \n",
    "    if auc or compare:\n",
    "        pts = np.array(list(zip(fpr,tpr))+[[1,0]])\n",
    "        p = Polygon(pts, closed=False, color='gold', alpha=.2)\n",
    "        ax.add_patch(p)\n",
    "        ax.annotate(  f'AUC = 0.79', (.4, 0.93), size=20, weight='bold', color='maroon');\n",
    "    else:\n",
    "        ax.plot(np.ones(5)*fpr[select], np.linspace(0,tpr[select],5), color='gold',alpha=.2, linestyle='-', linewidth=40);\n",
    "        ax.annotate(  f'TPR/FPR: {ratio[select-1]:.01f}', (fpr[select]-.01,text_y_pos[select]), size=16,rotation=90, weight='bold', color='maroon');\n",
    "    \n",
    "    if compare:\n",
    "        fpr_b= np.array([0,.031,.09,.15,.23,.4,.6,1])\n",
    "        tpr_b =np.array([0,.2,.5,.6,.71,.85,.91,1])\n",
    "        pts = np.array(list(zip(fpr_b,tpr_b))+[[1,0]])\n",
    "        p = Polygon(pts, closed=False, color='darkgreen', alpha=.5)\n",
    "        ax.add_patch(p)\n",
    "        ax.annotate(  f'AUC = 0.68', (.4, 0.75), size=20, weight='bold', color='white');\n",
    "        ax.plot(fpr_b, tpr_b, color='b');\n",
    "        ax.scatter(fpr_b, tpr_b, color='b', s=180);\n",
    "        \n",
    "        \n",
    "        \n",
    "    ax.plot(fpr, tpr, color='k');\n",
    "    ax.scatter(fpr, tpr, color='k', s=180);\n",
    "    ax.plot(np.linspace(0,1,5), np.linspace(0,1,5), color='r', linestyle='--');\n",
    "    label_font = {'size':'12', 'weight':'bold'}\n",
    "    ax.set_xlabel('False Positive Rate\\n(1-Specificity)',fontdict=label_font);\n",
    "    ax.set_ylabel('True Positive Rate\\n(Sensitivity/Recall)',fontdict=label_font);\n",
    "    ax.set_xlim(0, 1.02);\n",
    "    ax.set_ylim(0, 1.02);\n",
    "    return None  \n",
    "\n",
    "\n",
    "def update_roc_plot(select, auc, compare, ax):\n",
    "    ax.clear()\n",
    "    \n",
    "    draw_roc_plot(select, auc, compare, ax)\n",
    "    \n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "  \n",
    "def create_roc_plot(select=1, auc=False, compare=False):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "    draw_roc_plot(select=1, auc=False, compare=False,ax=ax)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# Hekper function to prepare the regression dataset\n",
    "\n",
    "def split_and_scale(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "def prep_regression():\n",
    "    data = pd.read_csv('Lecture_data/fish.csv')\n",
    "    # Prepare X and y\n",
    "    X = data[['Length1', 'Length2', 'Length3', 'Height', 'Width']]\n",
    "    y = data['Weight']\n",
    "\n",
    "    return split_and_scale(X, y)\n",
    "\n",
    "\n",
    "# Hekper function to prepare the classification dataset\n",
    "\n",
    "def prep_classification():\n",
    "    data = pd.read_csv('Lecture_data/wines_binary.csv')\n",
    "    \n",
    "    X=data.drop(columns=['is_good_quality'])\n",
    "    y=data.is_good_quality\n",
    "    \n",
    "    return split_and_scale(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d7673b-71a7-4c1e-aa2e-49e84f30ac9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:47:58.027327Z",
     "start_time": "2021-10-13T14:47:58.010958Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<center><h1 style=\"color:maroon\">Performance Metrics</h1>\n",
    "<img src=\"https://drive.google.com/uc?id=12A_ZQ1a-C_Lo-VCkvU0TD-AEYMXZMT0U\" style=\"width:1300px;\">\n",
    "    <h3><span style=\"color: #045F5F\">Data Science & Machine Learning for Planet Earth Lecture Series</span></h3><h6><i> by C√©dric M. John <span style=\"size:6pts\">(2023)</span></i></h6></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b3d00-e103-43ab-a870-7da43b210360",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Plan for today's Lecture üóì\n",
    "* Algorithm of the Day: Logistic Regression and KNN\n",
    "* Baseline score\n",
    "* Regression Metrics\n",
    "* Classification Metrics\n",
    "* ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21944f9f-2e95-45bc-995e-f5764db3e47d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## Intended learning outcomes üë©‚Äçüéì\n",
    "* Confidently choose the right evaluation metric\n",
    "* Compare different model performance\n",
    "* Use different metrics in CrossValidation\n",
    "* Use of KNN for classification and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8499db1-9f47-47ec-b38f-a673f2551153",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# Regression Dataset\n",
    "Today's dataset for regression: <a href=\"https://www.kaggle.com/aungpyaeap/fish-market\">Kaggle fish market dataset</a>.\n",
    "<img src=\"https://drive.google.com/uc?id=11nKFH6_UuaUexqoVQqEfSrKvDDdTQWVw\" style=\"width:1300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95fd08-82c1-43d0-986f-1e3710bd1dc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# Classification Dataset\n",
    "**<span style=\"color:teal\">Dataset for classification today:</span>** <a href=\"https://drive.google.com/uc?id=12A1GYnyQa3HJMKJnBNQHk4flA_l4_uA7\">UCI Wine Dataset</a><br>\n",
    "<img src=\"figures/wines.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd515d93-dd31-4501-a7ee-ec6b4b9ab574",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Algorithm of the Day: Classification with Logistic Regression\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?id=11rZhkAicPBeNHKositWRftquEN2KoYyx\" style=\"width:900px;\"><br>\n",
    " ¬© C√©dric John, 2023; Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a>\n",
    "<br>Prompt: Algorithm of the Day.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55222588-46fd-4c25-af9f-0ade2719a5e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# How can we achieve classification with two classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403647b0-6b76-417e-a16a-3d1da7d605e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<ul>\n",
    "<li>Predict the <strong>probability</strong> of an outcome (0 or 1)<ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd216b-3b31-44c6-bcc3-86bfbcdfb7ac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<p><img src=\"https://drive.google.com/uc?id=12Ei3cF_bi7D6EjVnObwkwKXPsYwt28fM\" width=\"1000\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849e57b-7e4e-4a6c-9557-a98eb035d5f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# Fitting a linear model in probability space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a94b2-fa82-4205-9954-7a4586acd89c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<p><img src=\"https://drive.google.com/uc?id=12ALOmXt3TnVpGB0nlya1SjsdEc9XRNXC\" width=\"1000\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10c5e6-6a0b-4a19-88a1-1b75c1e5f14c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<ul>\n",
    "<li>OLS too gradual and sensitive to outliers</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ffe6d7-a533-40bf-a478-af29e76cc71f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<ul>\n",
    "    <li>Values are not capped</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d9866-42dc-4bdd-95ff-2337f7404ae0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# The logistic function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447cfb9-e2ac-406a-a78b-9bc794d16c1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<ul>\n",
    "<li>We need a function that better represents probability<ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874078fc-778b-49d2-b6bd-d2554407a338",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<ul>\n",
    "<li>Values capped between 0 and 1<ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd88c6-edee-4eaf-8b85-168b33ad3a53",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<ul>\n",
    "<li>Less sensitive to outliers<ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd9668-81c5-4108-a412-f97abe9b820c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Logistic Function:\n",
    "\n",
    "$$\\sigma(X) = \\frac{1}{1+e^{-X}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc6b16c-a8a3-403d-b45f-1e1b98c479b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<p><img src=\"https://drive.google.com/uc?id=11s48xEjlEU9vWEKI9bP7KpiTC5gZgZja\" width=\"1000\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ed62b-a0b0-4fdd-abbb-1e75cbce3b01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# Fitting a linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27daa21-8b21-4bd3-a464-ee44edf2cdcc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<p><img src=\"https://drive.google.com/uc?id=11wOdqlyC5-0CrhOLJo_dvyJx2T44j5Df\" width=\"1800\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7a67a-5afc-4234-a62a-8a54e4ece833",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Clearly *NOT* a linear function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b64a1-7544-497e-b7ac-4c10b7c88bc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# From probability to logit to achieve linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6b735-c1eb-48b8-946d-aae73a8cf0c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$P_{y=1}$ can be simplified as $(P)$ (probability of positive outcome)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84b4dd-d5e1-4696-9ace-53e77a1d36f8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "By extension: $P_{y=0} = 1-P$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93bde2-f55e-4a5f-bcdb-996dd6e301c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Odds = $\\frac{P}{1-P}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51a8d99-43c0-465b-b9eb-0b696dd00566",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "if $P=0.8$, $odds =\\frac{P}{1-P}=\\frac{0.8}{0.2} = 4$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0541827-d2aa-47e3-acfd-24d65237d8dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "logit (\"log odds) = $ln(\\frac{P}{1-P})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d350f7-9464-4586-935a-04d0a260c9e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<p><img src=\"https://drive.google.com/uc?id=11wPUNG-TMt7lIaPVu-7MdSgq6-t7hWpB\" width=\"1800\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed5fea-c5c3-447f-9219-b3125385cf9c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "$$ln(\\frac{P}{1-P})=\\beta_0 + \\beta_1 x1 + ... + \\beta_n x_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd346b-e32a-4f6f-8464-521d80bdade0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "$$ln(\\frac{P}{1-P})=\\beta X$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383fe46-6155-4066-8f43-ab954e3cd4a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<p><img src=\"https://drive.google.com/uc?id=11j2QOk8eSGwAcnJxxs2pciFeuzmVefk8\" width=\"1800\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5065f-fe33-4c44-9488-5b319f33583e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Logistic Regression simply solves for $ln(\\frac{P}{1-P})=\\beta X$. We will see how on Wednesday."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8c947-2711-427b-a833-ebe267776ab9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Logistic Regression is a Linear Model -> Easy to interpret the parameters ($\\beta$'s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f55075-8c29-4e41-b222-32e18e723904",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Relatively efficient: the most common classifiers in industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480f89c-73fb-4e8b-a9f9-c7275f398b15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Logistic Regression in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902cda7-cec2-4ea6-b188-3f7ddf9160cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prep_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e060c7e-1df2-439d-a96a-fe68321cc06d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "accuracy_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64932125-a057-44a1-8eac-d1916d5f027f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Algorithm of the Day: K-Nearest Neighbors (KNN)\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?id=126wqxbkAMx8HTs6QuFzznk-IV1zaBHv2\" style=\"width:900px;\"><br>\n",
    " ¬© C√©dric John, 2023; Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a>\n",
    "<br>Prompt: Algorithm of the Day.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc8a9d4-5e7c-4c84-ab4c-14672e245da0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "K-Nearest Neighbors (KNN) is a non-linear, distance based model capable of solving both Regression and Classification tasks.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0921107-3bc0-4372-8e34-b4a605427181",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Looks at <code>K</code> closest samples to make a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd2af7-b489-4832-b77e-13ab4d0843bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Up to us to determine <code>K</code> (hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964cc19-adf0-48e1-8ea8-044b5b2eea19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* No parameters are trained: instead, the **entire training dataset** is kept in memory and compared to for each prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5305fd-1074-47a3-8264-5e4a8ffaf47c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Calculate distance from sample\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=12-T333hJEesJmh8HrxJuidqY_Tx-AFK0\" width=\"1200\"/>\n",
    "<a href=https://link.springer.com/chapter/10.1007/978-981-16-3342-3_10>Suddarao et al (2022)</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120cf167-79ba-4fe8-a5c0-4adda01ffc60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## KNN decisions\n",
    "**Majority vote for classification:**\n",
    "* For <code>k=6</code> Class A (4 vs 1)\n",
    "* For <code>k=3</code> Class B (1 vs 2)\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=12-T333hJEesJmh8HrxJuidqY_Tx-AFK0\" width=\"800\"/><br>\n",
    "<a href=https://link.springer.com/chapter/10.1007/978-981-16-3342-3_10>Suddarao et al (2022)</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b8556-e8cd-426c-a4f4-e100143c0ebd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Average value for regression:**\n",
    "* For <code>k=6</code> average 6 values\n",
    "* For <code>k=3</code> average 3 values\n",
    "\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=12-T333hJEesJmh8HrxJuidqY_Tx-AFK0\" width=\"800\"/><br>\n",
    "<a href=https://link.springer.com/chapter/10.1007/978-981-16-3342-3_10>Suddarao et al (2022)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912d2b7-103a-4f0f-96d7-3234c8b42daf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fcdf55-0da8-4e44-909b-a4a24fd563be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8983c5-fafb-4d38-83b0-0b641c659d76",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = accuracy_score(y_test,knn_model.predict(X_test))\n",
    "\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07885ea-8ec2-4e65-896f-5fe8fd6ac507",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Choosing k\n",
    "The optimal ùëò will vary from dataset to dataset.\n",
    "* Lower k values, less observations to use to make a prediction, prone to overfitting\n",
    "* Higher k values, signal can be diluted, prone to underfitting\n",
    "* <code>sklearn</code> default is 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4882ad57-ff71-4476-bf0d-11db19444ec4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Baseline Score\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?id=11p2OJb3t0QUoI9tmSNdOz0XZddINPWDs\" style=\"width:900px;\"><br>\n",
    " ¬© C√©dric John, 2023; Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a>\n",
    "<br>Prompt: Algorithm of the Day.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abbfd7-256c-4780-baaf-3c6da322e406",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What is a baseline score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56211ac-be09-49bd-a65b-a594a0855925",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Evaluation metrics are used to compare different iteration of a model, or different models against another.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab56676-85c7-41a4-b7d9-3ecc10d79ff6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We start with a baseline score for the initial model utilizing very simple strategies for prediction:\n",
    "* **Classification**: Predicts a random (balanced) or most frequent (imbalanced) class\n",
    "* **Regression**: Predicts a central tendency measure e.g. mean, median or mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b48529-fdfa-428c-aa2f-767eb6b5464c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## üíª Regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4ce45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T10:05:07.027533Z",
     "start_time": "2021-10-13T10:05:06.971Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prep_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc7fc6-6ea1-4ebc-b86c-4e59e6b4efec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T10:05:07.027533Z",
     "start_time": "2021-10-13T10:05:06.971Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_model = DummyRegressor(strategy=\"mean\") # Baseline\n",
    "\n",
    "dummy_model.fit(X_train, y_train) # Calculate value for strategy\n",
    "dummy_model.score(X_test, y_test) # Score model based on consistently predicting the strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda2226-7c46-41f0-820d-5b115cd010a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T10:05:07.028421Z",
     "start_time": "2021-10-13T10:05:06.973Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "baseline_model = LinearRegression().fit(X_train, y_train) # instantiate and fit model \n",
    "\n",
    "baseline_model.score(X_test, y_test) # Score model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fffd8a-bece-46da-a714-dbb59ddcd4c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### \n",
    "Why use a dummy model?\n",
    "* Scikit-learn objects can be chained within data pipelines\n",
    "* Move rapidly through each step of pipeline construction\n",
    "* Obstacles can be identifed downstream more quickly\n",
    "* Actual model can be substituted later in the pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8486598-bb84-46b1-a526-6f0804b14500",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Regression Metrics\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?id=125RoaTVPbjEpqCf7_X9TNxS0WdOhM8CW\" style=\"width:900px;\"><br>\n",
    " ¬© C√©dric John, 2022; Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a><br>\n",
    "<br>Prompt: four cute little bears standing in a row and sorted from left to right from tallest to shortest, digital art.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1290570e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Measuring a *distance* between y and $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b32e05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    " <img src=\"https://drive.google.com/uc?id=1245GsCoc3Uu41TwsNdqxv0uPF_qCMfvi\" style=\"width:800px;\">\n",
    "<a href=https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa>Grootendorf, 2021</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f37aa-c8af-4d00-bdc9-3f5756677278",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Mean Squared Error (MSE)\n",
    "$$\\text{MSE} = {\\frac{1}{n} \\sum_{i = 1}^{n} (y_i - \\hat y_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee933a-4a3c-4558-995f-80efed423a02",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Root Mean squared error (RMSE)\n",
    "$$\\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i = 1}^{n} (y_i - \\hat y_i)^2 }$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c53282-dd91-4bea-8280-94e73fe044e4",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Mean absolute error\n",
    "* Less sensitive to outliers\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y_i}|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a434702-1cdc-47c3-b8e3-ed6f11ac3aaf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Max Error\n",
    "$$ ME = \\max_{i=1}^{n} |y_i - \\hat{y_i}|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bf03ea-fbbb-43ab-a840-127714c04b4d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Coefficient of determination $R^2$\n",
    "$$ R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n}(y_i - \\overline{y})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a8aa9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Choosing the right regression metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f2cc0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use MSE when you need to penalize large errors / sign of error not important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb4dbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use RMSE when you want to penalize large errors, but see it in the unit of the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575d621",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use MAE when all errors, large or small, have equal importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6a658",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use Max Error when you want to limit the magnitude of the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23c385-0798-4d0a-b598-a43fe147f84c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use $R^{2}$ when you want a general/comparable performance metric / units not required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058de5a-bfc5-43dd-8396-f8cfc5014d15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## üíª Metrics in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44816e7c-fbfb-4159-9480-401861bbcc0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T10:05:07.029148Z",
     "start_time": "2021-10-13T10:05:06.978Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, max_error\n",
    "import math\n",
    "\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "rsquared = r2_score(y_test, y_pred)\n",
    "\n",
    "max_error = max_error(y_test, y_pred)\n",
    "\n",
    "print('MSE =', round(mse, 2))\n",
    "print('RMSE =', round(rmse, 2))\n",
    "print('MAE =', round(mae, 2))\n",
    "print('R2 =', round(rsquared, 2))\n",
    "print('Max Error =', round(max_error, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a23d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "üö®There is no standardized value for Mean Square Error, Root Mean Square Error and Mean Abosulte Error. Scores will be relative to the magnitude of the units within the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4c24a-bc8a-474f-b98d-ba511c3007ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### üíª Metrics during Cross-validation\n",
    "* A metric of choice can be specified directly with algorithms.\n",
    "* If <code>scoring</code> is not set, the model's default scoring metric is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2407f8-3589-476b-8945-3f59dd230354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T10:05:07.029993Z",
     "start_time": "2021-10-13T10:05:06.980Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# 5-Fold Cross validate model\n",
    "model = LinearRegression()\n",
    "cv_results = cross_validate(model, X_train, y_train, cv=5, \n",
    "                            scoring=['max_error',\n",
    "                                     'r2', \n",
    "                                     'neg_mean_absolute_error',\n",
    "                                     'neg_mean_squared_error']\n",
    "                           )\n",
    "pd.DataFrame(cv_results) # Cross validation output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c0bb7-d998-4e9a-a4c3-13ab1db4e1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T10:05:07.030556Z",
     "start_time": "2021-10-13T10:05:06.982Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cv_results['test_r2'].mean()# Cross validation results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea41152-4e4b-47f7-9096-352d8760a784",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Classification Metrics\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?id=11vFqBAgv12QOoRs7NohyB7_wvDcKVMEA\" style=\"width:900px;\"><br>\n",
    " ¬© C√©dric John, 2022; Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a><br>\n",
    "<br>Prompt: four different species of colorful flowers sorted by color\" by Paul Kleh.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d815783",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prep_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb09df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e861a17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c533d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test) \n",
    "y_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36d6c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Two possible correct outcomes for binary classification\n",
    " <img src=\"https://drive.google.com/uc?id=11hhMo0tbgG61H0umV_s1e9g5ZR18yjTF\" style=\"width:720px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d8ca8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **True Negative (TN):** A member of the negative (<span style=\"color:red\">0</span>) class correctly identified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774f335",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **True Positive (TP):** A member of the positive (<span style=\"color:blue\">1</span>) class correctly identified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222ff5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Two possible Errors\n",
    " <img src=\"https://drive.google.com/uc?id=11yeWaxeTyyUnLmKtOC0uMBrT-rqjZHBN\" style=\"width:720px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0bfaf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **False Negative (FN):** A member of the positive (<span style=\"color:blue\">1</span>) class identified as negative (<span style=\"color:red\">0</span>) (aka ***Type I Error***)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e02a77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **False Positive (FP):** A member of the negative (<span style=\"color:red\">0</span>) class identified as positive (<span style=\"color:blue\">1</span>) (aka ***Type II Error***)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcdb06-c6fa-4afd-a14b-c2d50b8c5d11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Confusion Matrix\n",
    "<img src=\"https://drive.google.com/uc?id=11ow07RtJkcsa8egdkiUFxAHzoS6BzlRX\" style=\"width:720px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7704364b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **Correct Values** on one of the two diagonals, matrix can be larger for multiclass classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b07c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **Often plotted with number of samples** or precentage of sample in each quadrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2982f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **Generally plotted as a heatmap** where the color represents the abundance in each quandrant (not here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec799b-484d-4307-888b-6c555ecd4455",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Accuracy\n",
    "Sum of the correct predictions divided by the sum of the overall number of predictions\n",
    "$$\\text{accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a753c-6880-4b9e-874c-4988e37ee4e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=11kx1FzJno0L8giQKlh5gtvHC2FMRjW4s\" style=\"width:720px\">\n",
    "$\\text{accuracy} = \\frac{4 + 3}{4 + 3 + 2 + 1} = 0.7$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d140a-d2e8-4293-ac1a-d04a277dec3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limitations of accuracy\n",
    "<img src=\"https://drive.google.com/uc?id=11qvDN7jVoVt9rbEIllebh1jlQY2a3KzD\" style=\"width:720px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e1d7d8-a705-404a-acc6-fe4f8e87fb6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "$accuracy = \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{0 + 99}{0 + 99 + 1 + 0} = 0.99$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487fb50-a796-4899-9178-dbe2f3ee6863",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "üö®Using accuracy alone can give overly confident scores, especially when dealing with imbalanced datasetsüö®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf91834",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Balancing datasets\n",
    "<img src=\"https://drive.google.com/uc?id=12-7bPfTCNNAwakeqFlEdnF-5nDrJ0E-I\" width=\"1500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53506d44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Why balancing?\n",
    "* ML algorithms learn by example \n",
    "* Will tend to predict under represented class poorly \n",
    "* ~30:70 split for binary classification would be considered imbalanced \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5228673b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Oversampling or Undersampling \n",
    "Duplicating instances of the minority class or sampling down the majority class.\n",
    "<img src=\"https://drive.google.com/uc?id=11r-ozAwbfoK8U7qgWw6ezmXMJtQ9abAP\" style=\"width:1200px\">\n",
    "<a href=\"https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t1\">Alencar, 2017</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae0b8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üö® Oversampling can cause data leakage between training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca410f9e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    " \n",
    "* Only use balancing techniques on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41412404",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* We want to keep our test set as representative of real life as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f7dc8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Synthetic Minority Over-sampling TEchnique - SMOTE \n",
    "SMOTE is an oversampling algorithm that generates new minority instances from existing minority instances based on linear combinations of existing points.\n",
    "<img src=\"https://drive.google.com/uc?id=11fjHaVEFamOmyzWlNohtLcMEYx3zRp0r\" style=\"width=1200px\">\n",
    "<a href=\"https://iq.opengenus.org/smote-for-imbalanced-dataset/\">Source: Maheshwari / OpenGenus</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec6465",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### üë∑ How SMOTE works:\n",
    "**1.** Using KNN find <span style=\"color:teal\">***k-nearest neighbors***</span> of minority sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c890d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**2.** Generate **<span style=\"color:teal\">*m* synthetic samples</span>** at random on the hyperplane defined by the *k-neighbors*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258caf6-f98b-4500-afe0-0f7de8195339",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Recall\n",
    "Measures the ability of the model to detect occurrences of a class.\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe801cff-21d6-4005-99a6-eccc6c08be10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=11kx1FzJno0L8giQKlh5gtvHC2FMRjW4s\" style=\"width:720px\">\n",
    "$\\text{recall=}\\frac{4}{4 + 1}=0.8$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c107d1-3afc-42dc-bd65-ba5be5757f6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limitations of recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d502baf-0e70-4470-b2f3-215ead58d8b5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=11z8D8vTujs0SidCByDSbIhmEYi8R8ysk\" style=\"width:720px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a18b324-7396-4eeb-98ec-94fc965dd462",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "$recall = \\frac{TP}{TP + FN} = \\frac{27}{27 + 3} = 0.89$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4214d3dd-6c38-458b-8427-23e11903e9c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* A lot of false positive acceptable for task such as cancer identification\n",
    "* But could also be terrible for a smoke alarm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc042f99-bbf2-4082-9839-41d0953e1eba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Precision\n",
    "Measures the ability of a model to correctly identify TPs.\n",
    "$$precision = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7d436-4d1d-47dc-9bba-7c05da94546b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=11kx1FzJno0L8giQKlh5gtvHC2FMRjW4s\" style=\"width:720px\">\n",
    "$\\text{precision}=\\frac{4}{4 + 2} = 0.67$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55cc41-b1ca-4b32-a4ec-3c53d48b9997",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limitations of precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d403fbe6-6925-409d-9298-5f0c5b41be8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=12BRkkKnctGOPO3j4juoFQyNbfQxjYMYT\" style=\"width:720px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff22032-2130-474c-845b-d67c0bb77773",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$\\text{precision} = \\frac{TP}{TP + FP} = \\frac{356}{356 + 44} = 0.89$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d12e43-193a-4c5a-b9f6-b3e311753e1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "$\\text{recall} = \\frac{TP}{TP + FN} = \\frac{356}{356 + 900} = 0.28$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc116727",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Other metrics similar to precision and recall:\n",
    "\n",
    "* Recall = <span style=\"color:blue\">True positive rate</span> = sensitivity = $\\frac{TP}{TP + FN}$\n",
    "* Specificity = $\\frac{TN}{FP + TN}$<br>\n",
    "* <span style=\"color:red\">False positive rate</span> = (1-specificity) = $\\frac{FP}{FP + TN}$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3860b0f-11e1-4367-af80-40a3c17f4391",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## $F_1-score$\n",
    "A combination of precision and recall into a single metric.\n",
    "$$F_1=2x\\frac{precision \\times recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d4dd2-d242-4ff1-bbd3-f041647a9866",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Also known as the harmonic mean of precision and recall\n",
    "* It will be influenced more by the lower of the two values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ab94b-aa65-4499-8026-01fbe1f1bd73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=11kx1FzJno0L8giQKlh5gtvHC2FMRjW4s\" style=\"width:720px\">\n",
    "$\\text{F}_1\\text{ score}=2 ¬∑\\frac{0.67 \\times 0.8}{0.67 + 0.8} = 0.73$<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372b1cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What each metric gives you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8783fff6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use **Accuracy** when you have balanced classes and predicting each class is important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaffe41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use **Recall** when it is important to identify as many occurences of a class as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3848b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use **Precision** when it is important to correctly identify the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbb938-a93b-40cb-a4cb-e263860560d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* üëâ Use **$F_{1}$** when you want a generic metric to compare across models and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec36bf-cc07-4c67-9ee2-b9cbff41cfca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## üíª Classification metrics in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448d248-101b-41ee-ae51-156c67d68a91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T10:05:07.031819Z",
     "start_time": "2021-10-13T10:05:06.996Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('Accuracy =', round(accuracy_score(y_test, y_pred), 2)) # Accuracy\n",
    "\n",
    "print('Precision =', round(precision_score(y_test, y_pred), 2)) # Precision\n",
    "\n",
    "print('Recall =', round(recall_score(y_test, y_pred), 2)) # Recall\n",
    "\n",
    "print('F1 score =', round(f1_score(y_test, y_pred), 2)) # F1 score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33a8fc-be49-47db-a44b-b98aae095377",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Decision Threshold (for binary classifiers)\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?id=11pFyOGIt21V4ZWtd9uINMI4jGOq5-wYN\" style=\"width:900px;\"><br>\n",
    " ¬© C√©dric John, 2022; Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a><br>\n",
    "<br>Prompt: A 35 mm photo of a Greek door step painted in vivid blue opening up in a white wall and showing the sea on the horizon.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a839625",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## üñ• <code>precision_recall_curve</code>\n",
    "The <code>precision_recall_curve</code> let us compare precision and recall for **binary classifiers** across a variety of thresholds.<br>\n",
    "We can use this to find a threshold that guarantees a score for one metric whilst maintaining a minimum score for the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0730ee-17c7-4350-b51e-ac4c8e35d92e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## The Precision-Recall Tradeoff\n",
    "* In **binary classification**: inverse relationship between precision and recall\n",
    "* Typically, we will trade one off against the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5413f91",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = create_plot();\n",
    "@interact(threshold=FloatSlider(min=0.01,max=0.99,step=.01,value=.5))\n",
    "def plot(threshold):\n",
    "    update_plot(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cca8c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "\n",
    "PrecisionRecallDisplay.from_estimator(model, X_train, y_train, ax=ax);\n",
    "ax.set_ylim(0.5, 1.01)\n",
    "ax.set_xlim(0, 1.01)\n",
    "ax.plot(np.ones(2)*0.8445266468790148,np.linspace(0.5,1.1,2), color='purple', linestyle='--')\n",
    "ax.plot(np.ones(2)*0.8445266468790148,np.linspace(0.5,0.8741316459178761,2), color='grey', linestyle='--')\n",
    "ax.plot(np.linspace(0,0.8445266468790148,2),np.ones(2)*0.8741316459178761, color='grey', linestyle='--');\n",
    "ax.annotate(  f'Threshold = 0.50', (.43,.82), size=12, weight='bold', color='grey')\n",
    "ax.annotate(  f'Precision: 0.84', (.01,.89), size=12, weight='bold', color='blue')\n",
    "ax.annotate(  f'Recall: 0.87', (.65,.52), size=12, weight='bold', color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45bb118",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## üç∑ Adjusting the Threshold\n",
    "What if I have specific requirements for my wine quality? For instance, let's say that I need a classifier that can give me at least a 90% precision on the win quality, with the maximum recall possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053fbd1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We can use the <code>precision_recall_curve</code> tool to identify the best threshold for our requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665fb69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_test, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74105bd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prc_df = pd.DataFrame(precision,columns=['Precision'])\n",
    "prc_df['Recall'] = recall\n",
    "prc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe53394",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prc_df[prc_df['Precision']>=.9].sort_values('Recall',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d25c21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "th_index = prc_df[prc_df['Precision']>=.9].sort_values('Recall',ascending=False).index[0]\n",
    "th_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d72e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " threshold[th_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9f7ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "\n",
    "PrecisionRecallDisplay.from_estimator(model, X_train, y_train, ax=ax);\n",
    "ax.plot(np.ones(2)*recall[th_index],np.linspace(0.5,1.1,2), color='purple', linestyle='--')\n",
    "ax.plot(np.ones(2)*recall[th_index],np.linspace(0.5,precision[th_index],2), color='orange', linestyle='--')\n",
    "ax.plot(np.linspace(0,recall[th_index],2),np.ones(2)*precision[th_index], color='orange', linestyle='--');\n",
    "ax.annotate(  f'Adjusted threshold = {threshold[th_index]:.02}', (.35,.85), size=12, weight='bold', color='orange')\n",
    "ax.annotate(  f'Precision: 0.9', (.01,.91), size=12, weight='bold', color='blue')\n",
    "ax.annotate(  f'Recall: 0.81', (.6,.52), size=12, weight='bold', color='red')\n",
    "ax.set_ylim(0.5, 1.01)\n",
    "ax.set_xlim(0, 1.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9edcac4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Receiver-Operator Curve Area Under the Curve (ROC-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d286570",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = create_roc_plot()\n",
    "\n",
    "@interact(x=IntSlider(min=1,max=5, values=1), auc=False, compare=False)\n",
    "def plot(x, auc, compare):\n",
    "    update_roc_plot(select=x, auc=auc, compare=compare, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de53d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## üç∑  ROC-AUC for our wine classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed03ea-07ed-4aed-81fb-034750bea184",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "* Unlike F1, recall, precision and accuracy- AUC is not dependent on a threshold chosen\n",
    "* This makes it a great metric for measuring a models general performance üí™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3cfb6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T10:05:07.032517Z",
     "start_time": "2021-10-13T10:05:07.004Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute AUC score\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd397c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_prob_knn = knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19503c67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc_score_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "auc_score_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f581ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute AUC score\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_prob[:,1], drop_intermediate=False)\n",
    "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_prob_knn[:,1], drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6095e19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "\n",
    "ax.plot(fpr_lr, tpr_lr, label='Logistic Regression', linewidth=2)\n",
    "ax.plot(fpr_knn, tpr_knn, label='KNN classifier', linewidth=2)\n",
    "ax.plot(np.linspace(0,1,5), np.linspace(0,1,5), color='k',linestyle='--')\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42294fa4-3772-4a1a-b291-5f734f04bf09",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# Suggested Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fc53a-1d05-44a0-92cb-248fc73a0e51",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "## üì∫ Videos \n",
    "#### Short videos from my Undegraduate Machine Learning Classes:\n",
    "\n",
    "* üìº <a href=\"https://youtu.be/wZc0N3TOX_Y?list=PLZzjCZ3QdgQCcRIwQdd-_cJNAUgiEBB_n\">Types of Machine Learning</a>\n",
    "* üìº <a href=\"https://youtu.be/Ij9s_eSC5C4?list=PLZzjCZ3QdgQCcRIwQdd-_cJNAUgiEBB_n\">Performance Metrics in Classification</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e41ff-612f-450a-808e-14c875b68fdb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "## üìö Further Reading \n",
    "* üìñ <a href=\"https://pubs.acs.org/doi/10.1021/acs.jcim.1c00160#\">GHOST: Adjusting the Decision Threshold to Handle Imbalanced Data in Machine Learning</a> by Esposito et al., 2021\n",
    "* üìñ <a href=\"https://towardsdatascience.com/how-to-add-decision-threshold-tuning-to-your-end-to-end-ml-pipelines-7077b82b71a\">How to add Decision Threshold tuning to your end to end ML pipelines</a> by Jerome Kafrouni, 2021\n",
    "* üìñ <a  href=\"https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\">The ROC Curve</a> by Google Developers\n",
    "* üìñ <a href=\"https://www.mygreatlearning.com/blog/knn-algorithm-introduction/\">A good introduction to KNN</a> by Marina Chatterjee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541581bb-848a-42b6-85fe-febbf5010938",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## üíªüêç Time to Code ! "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "rise": {
   "scroll": true,
   "theme": "serif",
   "transition": "none"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "voila": {
   "strip_sources": "False",
   "template": "reveal"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
