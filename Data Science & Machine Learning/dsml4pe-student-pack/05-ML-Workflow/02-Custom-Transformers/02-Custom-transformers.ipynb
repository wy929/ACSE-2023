{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35736e8d",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1-cL5eOpEsbuIEkvwW2KnpXC12-PAbamr\" style=\"Width:1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f8371",
   "metadata": {},
   "source": [
    "# Writing Custom Transformers\n",
    "\n",
    "In the next few exercise, you will learn to take your code closer to `production` level. This means getting out of the `Juoyter notebook` and into proper class files. The benefit from this is that you will be able to use your different transformers directly into your `pipelines`, but also that (at least in theory) you will be able to deploy your machine learning model on the cloud, both for **training** and for **prediction**.\n",
    "\n",
    "Being comfortable with going from `Jupyter notebook` to `Python class` is an important skill that you need to master: this might be the difference between getting the job as a data scientist during interview, or not. And it will be an expectation for the assessed coursework.\n",
    "\n",
    "For this exercise, you can use this `Jupyter notebook` to test your code and try idea. Most, if not all, of the code you already wrote in your previous exercise. You will find in this folder several `.py` files: use `VSCode` (or the IDE of your choice) to edit them: the skeleton of each function is already written for you, you simply need to modify the code to test your functions.\n",
    "\n",
    "The goal is to write one `transformer` class that will inherit from `TransformerMixin` and `BaseEstimator`, and have three main methods that need to be implemented: `__init__(self)` which is called when the transformer is created, `fit(self)` which is when the transformer `learns` the different statistics of the data (if needed: not all transformers need to do something at `fit(X,y)` time, and yours might not), and of course `transform (self, X, y)`, which takes the `X` features, transform them, and return the transformed values (and only those).\n",
    "\n",
    "# Reading the data\n",
    "\n",
    "I have already split the data for you into a `train_set` and a `test_set` in the cell below. Note that because the data is a `Time Series` I have split it in a way that all of our `train_set` lies between 2003 and 2011 whereas the `test_set` represents the years 2012, and 2013.\n",
    "\n",
    "Once you have executed the cell below, look at the `train_set` to see what the features we are going to work with look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell first in order to be able to see changes in your \"custom_transformers.py\" file without needing to restart your kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9cc116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbta.utils import download_data\n",
    "download_data(id='1ftc-lXujVjX9he3xpX9uC6-9MKxURt50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4110581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_set = pd.read_csv('raw_data/train_temperatures.csv')\n",
    "test_set = pd.read_csv('raw_data/test_temperatures.csv')\n",
    "\n",
    "X_train = train_set.drop(columns='AverageTemperature')\n",
    "X_test = test_set.drop(columns='AverageTemperature')\n",
    "\n",
    "y_train = train_set.AverageTemperature\n",
    "y_test = test_set.AverageTemperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37375b75",
   "metadata": {},
   "source": [
    "# Encoding the `month`\n",
    "\n",
    "It makes intuitive sense that adding information about the time of the year will help us being more predictive in our model. The month comes in the form of a `string` but also are often referred to as 1, 2, 3, ... 12: so we could use an `OrdinalEncoder` to convert the months into integers that represent their position.\n",
    "\n",
    "Let's try to do this. Create a simple pipeline that you can call `simple_pipe` and that includes the following:\n",
    "* A `SimpleImputer()` and a `StandardScaler()` for the 'Latitude', 'Longitude', and 'TempPreviousMonth'\n",
    "* An `OrdinalEncoder()` for the `month` column\n",
    "* A `LinearRegression()` model\n",
    "\n",
    "Fit this pipeline, and calcuate the `root mean squared error` on the `X_test`. Save this value into a variable called `base_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe15eb",
   "metadata": {},
   "source": [
    "### ☑️ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e63557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('ordinal_encoding',\n",
    "                         score = ordinal_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfcae16",
   "metadata": {},
   "source": [
    "# Preserving the ordinal nature of `month`\n",
    "\n",
    "Intuitively, we should realise that we have lost an important dimension here. We simply converted the strings into number: `Jan`:`1`, `Feb`:`2`, etc... The issue with this encoding is that it does not really reflect the nature of seasonality: **November and December are 1 unit away** (12-11), whereas **December and January are 11 units away** (12-1). This is a common problem of data that are cyclical in nature: you will have this issue when encoding dates and times, seasons, or even angular information.\n",
    "\n",
    "Luckily, there is an elegant solution to this problem. Have a look at <a href=\"https://towardsdatascience.com/cyclical-features-encoding-its-about-time-ce23581845ca\">this excellent blog post to understand the concept better</a>, and then come back here.\n",
    "\n",
    "If you have read the post, now you should understand that we can encode cyclical data using two features: the `sin` and the `cosin` of the angle (in degrees `radian`) of the cycle. Given that a full circle in `radian` is equal to $2*\\pi$, we can divide it into 12 equal segment and multiply this by the month number. In other words, $January=\\frac{2*\\pi}{12}$, $February=2*\\frac{2*\\pi}{12}$...$December = 12*\\frac{2*\\pi}{12}$. Then, we simply create two new features (`sin_month` and `cos_month`) to encode this angular representation of the month.\n",
    "\n",
    "Go ahead and implement the `encode_month(month)` function. It should do the following:\n",
    "1. You pass the entire `month` series as the input of the function\n",
    "2. Use a dictionary to convert the strings into number between 1 and 12, as explained above.\n",
    "3. Calculate the correct angle for each month as per the solution suggested above (I suggest using a `lambda` function).\n",
    "4. Return a `DataFrame` that contains two columns: the `sin_month` and the `cos_month`, i.e. respectively the `sin` and `cosin` of the month converted to degree radian\n",
    "\n",
    "Then, create a `X_train_prep` and `X_test_prep` dataframes that are copies of `X_train` and `X_test` (we want to preserve the original values). You can then use this function to create two new features `[\"sin_month\", \"cos_month\"]` for your `X_test_prep` and `X_train_prep`. \n",
    "\n",
    "Finally, create a new pipeline that will have the following elements:\n",
    "\n",
    "* a `SimpleImputer(strategy='most_frequent')` for 'sin_month' and 'cos_month'\n",
    "* a SimpleImputer() and a StandardScaler() for 'Latitude', 'Longitude', and'TempPreviousMonth'\n",
    "* a `LinearRegression()` model\n",
    "\n",
    "Fit this pipeline on `X_train_prep` and `y_train`, and save the `root mean squared error` of the `X_test_prep` as `encoded_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d09792",
   "metadata": {},
   "source": [
    "### ☑️ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec186f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('month_encoding',\n",
    "                         test_set = X_test_prep,\n",
    "                         score = encoded_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4f3cb",
   "metadata": {},
   "source": [
    "# `MonthEncoder`\n",
    "\n",
    "What we did in the last section worked well! But it is a pain to apply it manually. So here you  will implement the transformation from the months in `string` format (`Jan`, `Feb`, etc...) into the `sin` and `cosin` values into a `Transformer class`. Make sure that the class returns a `pd.Dataframe` with only 2 features (`sin_month` and `cos_month`). Note that this is only necessary to be able to see the transformed values nicely, and also to past the test in this notebook. Strictly speaking, you can return a `np.ndarray` as most transformers do (but returning a `DataFrame` is very little extra effort and is well worth it).\n",
    "\n",
    "Then, create a pipeline that will contain the following:\n",
    "\n",
    "* a `SimpleImputer(strategy='most_frequent')` and `MonthEncoder` for 'month'\n",
    "* a `SimpleImputer()` and a `StandardScaler()` for 'Latitude', 'Longitude', and'TempPreviousMonth'\n",
    "* a `LinearRegression()` model\n",
    "\n",
    "call this pipeline `final_pipe` in your notebook, and fit it with your `X_train` and `y_train`. Make sure you obtain the same score as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a88ce2d",
   "metadata": {},
   "source": [
    "### ☑️ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('transformer',\n",
    "                         pipe = final_pipe\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d525f5bc",
   "metadata": {},
   "source": [
    "# 🏁 Finished!\n",
    "\n",
    "Well done! <span style=\"color:teal\">**Push your exercise to GitHub**</span>, and move on to the next one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
