{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a05c78",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1-cL5eOpEsbuIEkvwW2KnpXC12-PAbamr\" style=\"Width:1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07834b87",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1fyePzwUvVF9OBK2q9-t9f8fojx6Sp0Es\" style=\"Width:250px, height:250px\">\n",
    "\n",
    "# Movie Reviews\n",
    "\n",
    "In this and the following exercise, you will use the famous <a href=\"https://www.imdb.com/\">IMDB movie dataset</a> as saved on <a href=\"https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\">Kaggle</a>. The Kaggle dataset contains 50K movies, but this tends to crash your kernel and be slow. The version I give you today has been downsampled to 25k reviews..\n",
    "\n",
    "Your task is is to classify movie reviews as positive or negative. You will:\n",
    "\n",
    "- Preprocess the reviews (remove punctuation and lower case)\n",
    "- Vectorize a Bag of words\n",
    "- Train and score a Naive Bayes model\n",
    "\n",
    "Let's start by importing the data. We will use `cross_validation` today so we won't worry too much about a test set (though for serious NLP you would want to have one!)\n",
    "\n",
    "P.S. Look on the photo at the spelling of results. Dall-E is getting better in 2023, but not yet perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbta.utils import download_data\n",
    "download_data(id='1DtuD7LtrfUfGSZioocYZvTzkpvLwgqwA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"raw_data/IMDB_dataset_25k.csv\")\n",
    "\n",
    "# This data is too large for most of your systems, so we will take only 10% of the dataset:\n",
    "data = data.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d1eb4",
   "metadata": {},
   "source": [
    "The dataset is made up of positive and negative movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b7103",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Create a new column in `data` called `clean_text`. This will contain a cleaned version of the `review`, where you will remove punctuation,  lower case the text, remove digits, remove english stop-words, lemmatiaze your text, and tokenize it. We will preserve the text as a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's make sure that the stopwords from NLTK are downloaded on your system:\n",
    "\n",
    "from nltk import download\n",
    "\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ab804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reduce the memory footprint\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764743c9",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code\n",
    "\n",
    "Note: this only tests if you achieve the mandated **precision** and **recall** on an unseen dataset. It does not check the quality of your code or the completeness of your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('check_data',\n",
    "                         sentence = data.clean_text[0],\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553acad",
   "metadata": {},
   "source": [
    "## Bag-of-Words modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98b19a",
   "metadata": {},
   "source": [
    "Using `cross_validate`, score a Multinomial Naive Bayes model trained on a Bag-of-Word representation of the texts. Save its test accuracy as a variable named `bow_accuracy`. <details><summary>hint</summary>Use a `CountVectorizer`!</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d95be",
   "metadata": {},
   "source": [
    "## N-gram modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59549ed",
   "metadata": {},
   "source": [
    "üëá Using `cross_validate`, score a Multinomial Naive Bayes model trained on a 2-gram Bag-of-Word representation of the texts. You will use again the `CountVectorizer()` class but need to choose the right parameters. Save the test accuracy of your cross_validation as a variable named `ng_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2185567",
   "metadata": {},
   "source": [
    "## Assessing your model\n",
    "\n",
    "Which model performed better, and why do you think that is?\n",
    "\n",
    "<details><summary>Solution</summary>We would expect the N-Gram model to outperform your Bag-of-Words by a small margin. However, because of our reduced dataset, this is not really the case here. N-Grams are normally better (though more computationally costly) because they capture the context of the words around a single token. This give more meaning to words that could otherwise have different meaning depending on the context. You will see this furhter in deep-learning, when you learn about the attention mechanism for `Transformers`, the de-facto go-to architecture for NLP today.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf354e",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code\n",
    "\n",
    "Note: this only tests if you achieve the mandated **precision** and **recall** on an unseen dataset. It does not check the quality of your code or the completeness of your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('model_performance',\n",
    "                         bow_model = bow_accuracy,\n",
    "                         ng_model = ng_accuracy\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48e3ac",
   "metadata": {},
   "source": [
    "# Saving your data\n",
    "\n",
    "To save time, we will reuse the preprocessed data in the next exercise. Therefore, save the `data` dataframe as a `csv` file on the path `../02-Tuning-for-NLP/raw_data` as `processed_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6481d85",
   "metadata": {},
   "source": [
    "# üèÅ Finished!\n",
    "\n",
    "Well done! <span style=\"color:teal\">**Push your exercise to GitHub**</span>, and move on to the next one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
