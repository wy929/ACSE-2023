{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6da7ab",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1-cL5eOpEsbuIEkvwW2KnpXC12-PAbamr\" style=\"Width:1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093dd99",
   "metadata": {},
   "source": [
    "# Predicting Nepal earthquake damage on buildings using Ensemble methods\n",
    "\n",
    "In this exercise, you will use `Ensemble` learning to work on earthquakes again. However, this time you will use a different dataset and predict the damage inflicted on buildings in case of a major Earthquakes in Nepal. \n",
    "\n",
    "## Scientific Background\n",
    "Every year The National Earthquake Information Center (NEIC) records an average of 20,000 earthquakes all around to world. This number is fairly large, and implies an average of 50 earthquake occured  each day$^{[1]}$. Of course, the magnitude of most of these Earthquakes is fairly low.\n",
    "\n",
    "## Data\n",
    "In 2015 April 25, an intense earthquake occured in Central Nepal at local time of 11:56 a.m. The data used here was collected through surveys by [Kathmandu Living Labs](http://www.kathmandulivinglabs.org/) and the [Central Bureau of Statistics](https://cbs.gov.np/). This data is one of the largest post-disaster dataset ever collected, and it includes a wide range of information.\n",
    "\n",
    "## Objective\n",
    "Your goal is to predict the level of damage sustained by different buildings during the 2015 ***Gorkha earthquake*** in Nepal. Your goal, by the end of this notebook, is to obtain **>70% accuracy in your prediction**. \n",
    "\n",
    "***<span style=\"color:teal\"> Acknowledgement</span>***:Thanks to Parastoo Salah for assembling an initial version of the dataset used in this notebook!\n",
    "\n",
    "\n",
    "# Opening the data\n",
    "\n",
    "Open the data in `earthquake_nepal.csv`,  separate the target (`damage_grade`) and the features, and do a train_test_split with 80% in the `train_set` . <br>\n",
    "Convert your `y_train` and `y_test` to categorical data using a `label_encoder`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbta.utils import download_data\n",
    "download_data(id='1a4du6aGHJI2bM6UetT9N2Snqe1d3oEbR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabd805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395835b4",
   "metadata": {},
   "source": [
    "# Ensuring Data Quality\n",
    "* Check for missing data\n",
    "* Check what data types are present in your dataset: is it all `numerical`, or do you have `categorical` data?\n",
    "* Plot a `heatmap` to check for strong co-linearitu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082bbab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9864515",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Because we will be using the data multiple times on different classifier, it will be more convenient today to prepare it once using a `data preprocessing pipeline`, and then simply re-used the already preprocessed data. This will save us a bit of time at training time, and a lot of hassle (our pipelines won't get overly complicated). Of course, the drawback is that we won't be able to consume raw data straight into our model, but we will worry about this in our next exercise.\n",
    "\n",
    "So, prepare a preprocessing pipeline named `preproc` that will do the following:\n",
    "* `OneHotEncoding` on any categorical data\n",
    "* `StandardScaling` of numerical data\n",
    "\n",
    "Then, fit `preproc` on `X_train`, and go ahead and transform `X_train` and `X_test` (simply save the transformed versions back to the original names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee994c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6940f2f5",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "import scipy\n",
    "\n",
    "result = ChallengeResult('data_preproc',\n",
    "                         X_train_shape = X_train.shape,\n",
    "                         X_test_shape =  X_test.shape,\n",
    "                         sparsity = scipy.sparse.issparse(X_test)\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184783d",
   "metadata": {},
   "source": [
    "# Dummy modelling\n",
    "\n",
    "Our first step is to understand what the preformance of a `Dummy Model` looks like. Go ahead and create a `DummyClassifier`, choosing the `strategy` that will give you a similar distribution of prediction than the actual distribution of the class. Then, fit it to `X_train` and `y_train`, and generate an accuracy score (save this into a variable called `dummy_score`.\n",
    "\n",
    "Is the accuracy of the dummy model any good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7aa2aa",
   "metadata": {},
   "source": [
    "# Linear Model\n",
    "\n",
    "Let's see if a linear classifier would beat the dummy model! Using a `LogisticRegression` classifier, do the same process as for the `DummyClassifier` described above, but save the new accuracy score into a variable named `linear_score`.\n",
    "\n",
    "Does `LogisticRegression` beat your `DummyClassifier`, and does `LogisticRegression` give you the `>70% accuracy` we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bbe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be53b04",
   "metadata": {},
   "source": [
    "# KNN model\n",
    "\n",
    "Using a K-nearest neighbour classifier, do the same as above, and save the score as `knn_score`. Is `knn_score` > 70%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9df7ee",
   "metadata": {},
   "source": [
    "# Linear SVC using the `SGDClassifier` class\n",
    "\n",
    "Finally, use a `linear SVC` by calling an instance of `SGDClassifier` and setting the paramaters of `loss=\"hinge\"` and `max_iter=3000`. Save the score of this classifier as `sgd_score`. Is `sgd_score` > 70%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edffa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16875faa",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Finally, use a `DecisionTreeClassifier` to see how an individual decision tree would perform. Save the score of this classifier as `tree_score`. Is `tree_score` > 70%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ceb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff731e",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('initial_models_results',\n",
    "                         dummy_score = dummy_score,\n",
    "                         linear_score =  linear_score,\n",
    "                         knn_score =  knn_score,\n",
    "                         sgd_score =  sgd_score,\n",
    "                         tree_score =  tree_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b0af5d",
   "metadata": {},
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "By now, you have a pretty good feel for what accuracy you can get with a linear model (`LogisticRegression`) and a non-linear model (`KNeighborsClassifier`). Of course, we have not yet tweaked their hyperparameters, but we will leave this for last.\n",
    "\n",
    "Now is time to see how well a plain-vanilla `RandomForestClassifier` performs on this dataset. Save your `accuracy_score` in a variable called `rf_score`. Is `rf_score` > 70%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c455d74",
   "metadata": {},
   "source": [
    "# Boosting our performance with `BaggingClassifiers`\n",
    "\n",
    "The `RandomForestClassifier` comes close to meeting our required `>70% accuracy` score: it is definitely a better model than any of the previous ones we tried. But `RandomForest` is simply a version of a `Bagging Algorithm`, where multiple `DecisionTreeClassifiers` are trained on different versions of the same dataset (this is where the `bagging` term comes from - as in getting different samples out of the bag). \n",
    "\n",
    "Let's try if we can boost the performance of our `KNeighborsClassifier` by bagging it. Create a `BaggingClassifier` (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\">sklearn documentation</a>) with a plain vanilla `KNeighborsClassifier` as your base estimator, a total of 15 knn estimators, each trained on a maximum of 50% of the dataset and only 50% of the features. Set the `random_state=42` to ensure you pass the test. See what the performance of this algorithm is, and save your score in a variable called `knn_bag_score`.\n",
    "\n",
    "**Warning**: KNN will take a long time to come to a prediction, so creating your `y_pred` will be long (but training is fast). Be patient! ‚òï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f6c49",
   "metadata": {},
   "source": [
    "<details><summary>üí° Observations</summary><br>\n",
    "    We can see that the bagged version of the KNN outperforms the single KNN by at least 6-7%! This is pretty impressive. <br>It does not, however, outperform our RandomForest classifier. This is in part because we trained fewer individual predictors: the fact that at inference time KNNs are slow makes them less practical for this purpose than the decision trees.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a917ca1e",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e93b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('boosting_score',\n",
    "                         rf_score = rf_score,\n",
    "                         knn_bag_score =  knn_bag_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ff29d",
   "metadata": {},
   "source": [
    "# Prediction using heterogenous classifiers\n",
    "\n",
    "So far, we have used two `Ensemble` classifier: a `RandomForest` and a `Bagged KNN` classifier. You have seen that they both outperformed their non-bagged versions (`DecisionTreeClassifier` and `KNeighborsClassifier`). But what they have in common is that they are composed of a homogeneous ensemble of classifiers (either only `DecisionTrees` or only `KNeighborsClassifier`).\n",
    "\n",
    "Sometimes, it might be beneficial to use a heterogenous ensemble of classifiers to boost our performance. We can do this via two main classes in `sklearn`: the `VotingClassifier` and the `StackingClassifier`.\n",
    "\n",
    "## `VotingClassifier`\n",
    "\n",
    "Let's start with `VotingClassifier` as this is the most straightforward class. All it does is train a list of classifiers, and then agglomerate their results (either the predicted class (**hard voting**) or the predicted probabilities (**soft voting**)).<br>\n",
    "Create a `VotingClassifier` composed of:\n",
    "1. One `LogisticRegression` \n",
    "3. One `SGDClassifier(loss='hinge', max_iter=3000)`\n",
    "4. One `KNeighborsClassifier`\n",
    "5. One `RandomForestClassifier`\n",
    "\n",
    "Call this classifier `voting_classifier`, and save its performance in a variable called `voting_accuracy`. Do we outperform our `RandomForest` and the `bagged KNNs`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf596cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07048894",
   "metadata": {},
   "source": [
    "<details><summary>üí° Observations</summary><br>\n",
    "    The performance should be in the lower 60%, so not as good as our bagged algorithm. This is because we are not weighting our outputs (see below).</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bcfd54",
   "metadata": {},
   "source": [
    "## `StackingClassifier`\n",
    "\n",
    "The `VotingClassifier` is somewhat limited in that it takes the output of our classifiers, and simply uses this to come up to a classification. You can, of course, also work with the `weights` hyperparameter of this class to give different weights to the output of each individual classifier. In theory, you could tweak those using a `GridSearchCV` or `RandomizedSearchCV`: feel free to try this if you want.\n",
    "\n",
    "But I think that a better way to go forward is to use a `StackingClassifier`: unlike a `VotingClassifier`, the strategy behind a `StackingClassifier` is to train one final model that uses the output of your stacked models as inputs. In other words, we can train any model we want (even neural networks!) on the output of the different classifiers.\n",
    "\n",
    "Let's go ahead and do this using the same list of models as above for our `StackingClassifier`, but in addition, using another `LogisticRegression` as our `final_estimator`. Use a `cv=5` to train your `StackingClassifier` (as always, consult the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html\">sklearn documentation</a> if you want to learn how to properly use this classifier.\n",
    "\n",
    "Save your `X_test` accuracy score under a variable named `stacking_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c03007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc51d2b",
   "metadata": {},
   "source": [
    "<details><summary>üí° Observations</summary><br>\n",
    "    This time, we outperform our RandomForestClassifier by about 2%. This is already better, but not yet >70%. Don't worry: we will achieve this in our next exercise.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8560ce6",
   "metadata": {},
   "source": [
    "# Saving `preproc` to reuse it\n",
    "\n",
    "Well done! You are nearly done. In the next exercise, we will reuse the same dataset, and thus we will need to use the same `preproc` pipeline. We could of course simply rewrite the code, and retrain `preproc`. The pipeline is simple enough that this won't be any trouble.\n",
    "\n",
    "However, we will use this as an opportunity to learn how to save and open `sklearn` transformers and models to disk. This means you can save an `sklearn` object, and send it to whoever needs to use it.\n",
    "\n",
    "For this, we will simply use the `joblib` library: <a href=\"https://scikit-learn.org/stable/model_persistence.html\">read to sklearn documentation</a> to know why to use joblib rather than pickle, and how to do this. Then, save your trained transformer direction into the folder of the next exervise (use this path: \"../04-XGBoost/preproc.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdba52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa8e4c",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('stacking_score',\n",
    "                         voting_score = voting_accuracy,\n",
    "                         stacking_score =  stacking_accuracy\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857aa3fd",
   "metadata": {},
   "source": [
    "# üèÅ Finished!\n",
    "\n",
    "Well done! <span style=\"color:teal\">**Push your exercise to GitHub**</span>, and move on to the next one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
